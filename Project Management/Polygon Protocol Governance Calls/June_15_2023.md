# Polygon Protocol Governance Call (2023-06-15 16:01 GMT+1) - Transcript


### Attendees
0x2, Alex PFL, Ben Sparks, Dimitri Nikolaros, Ely x0, Fireflies.ai Notetaker Luther, George Serntedakis, Harry Rook, Jackson Lewis, Jason Windawi, Jeremy Feral, Jerry Chen, Kasper van der Valk, Manav Darji, Manav Darji's Presentation, Mateusz Rzeszowski, Michael Mugno, Michel Muniz, Mihailo Bjelic, Nimit Bavishi, Paul O'Leary, Pratik Patil, Raneet Debnath, Sahil Kamra, Sandeep Sreenath, Sandeep Sreenath's Presentation, staking 4all, Tanisha Katara, Tom Murphy, Vedant Patel, WebDev StakeWorks


## Transcript

**This editable transcript was computer generated and might contain errors. People can also change the text after it was created.**

**Harry Rook:** Well, thank you guys for joining Polygon Protocol Governance call, number four, good morning, good afternoon. Thank you all for taking the time to to join. In terms of agenda points for today, there are two main buckets, really the first being two proposed upcoming folks. The first being Indor. The second being Aalborg.
 Yeah, once we've gone through that, which will kind of include a Node contents which for Indor be picked, the proposed Timeline, you know, When will it go to Mumbai? What are the dependencies there and then when will we look to potentially roll out on Mainnet and the same will go for the elbow fork as well?
  And with that I believe Indor will be the first of the two and so we'll be looking to update. Pip 12, last call status on this call today as well and agree. That's the correct decision. And yeah, in like a different book it we've got some kind of more forward-looking updates. Jerry, Chan is here who will give a brief overview on parallelization, which is kind of take some ideas from Block STM, which is an exciting.
  Potential upgrade to increase the throughput of the chain. And then we also have though, guard, who will be giving a brief overview on some of his thoughts around me v on polygon.
 And yeah, with that said, I'll hand it over to Sandeep or Pratik who can give an overview of of the potential indoor hard fork. You know, when will it go? I potentially, what kind of testing are we yet to complete at? Yeah. When we can expect a main announcement.

**Sandeep Sreenath:** Sure. Thanks. Thanks a lot Harry. So yeah I'll start with the timelines because I think we've already covered, you know, the both the topics PIP 11 and 12 in detail in the Last Call but I have some of my teammates Pratik and Manav who will still be covering it a bit. And also discussing more about the testing testing strategies that we used and the methodology that we use.
Um so yeah, before that, you know, just an update on the timelines, I think most of you guys know that we have set June 20th as the hard forth date for PIP 12 which is the state sync, you know, the fix for the States in tissue and we'll be observing on Mumbai testnet for around a week's time. And then ensure that everything is working fine. Like we have a few test cases that that we are also planning to run on Mumbai after deploying.
Um so we have already run extensive testing in the devnets and we haven't seen any issues and like whatever issues that we saw have been already fixed. And yeah, so the the idea is to observe in the Mumbai testnet for a week around 27th. We will take a call whether we are going ahead with Mainnet, if everything looks good, then we will be Table tag and be hard for date. Tentatively will be July 11th? Like I said, if everything goes well, and
Yeah, this is the plan for PIP 12, which is the fix for the state sync issue. And for the Milestones release, which is PIP 11 for, you know, faster of deterministic finality. We will be you know, again, we are targeting around July and for Mumbai like we want to get this done and then we'll start working on the
You know, on ensuring that we have a release for that and doing all the tests. Like, so one other update I want to give is that we had the audit results and it looks very positive. They're having been any bugs in the main flow you know like there were some minor suggestions mostly in the test cases and you know some documentation and error handling which have all also been already you know. Like all the suggestions have been incorporated and you recent it back to the audit company for, you know, for getting the final review out. So yeah that's that's regarding PIP 11 and I'll pass it over to Pratik here. Yeah, Pratik. If you can present about PIP 12 which will be the immediate card for that we are working.

**Pratik Patil:** Yeah, sure.
So this is the like have shared the link to the PIP 12. I'll be giving a brief overview of this and then we'll go and cover testing. What, what all testing we have done. So basically,
There was a issue, because of which, the network like experience deep reorgs, and the root cause of this was related to state sync transactions written from Heimdal. So,, during the reorg, when there are merges back, what happens, is the incoming chain is being validated by the current node which is importing that you are. And during these, the states in transactions, like if there is a first block of a sprint, every sprint, we get the state saying transactions from him doll by providing a window to him. That basically, so that him does gives all the states in transactions that has happened during this window and then the states in transactions. Are then again, executed while importing the same, you know what used to happen is like when there were two different forks in the time taken
To my node, on my block, on each nodes were different, which resulted. So basically this window that I'm talking about, it includes two different parameters. First one is from ID and second one is two time. So basically we say him doll like the board tells its local aimdall. That it gives me all the states in transactions that has happened.
From this from ID which is the last it'sync ID plus 1 till the two time. So this window is changed because yeah, thanks sandeep for sharing the PAB. So basically this window gets changed because the two time is taken from the local block. But instead, it should be taken from the incoming blockchain and because of the differences in this two time, the window is shortened for one chain and like there is a difference between this window which results in different number of safety transactions written from him doll. And because of this, we get this bad luck error. And we found out like the initial issue occurred, because the two time was different. so we fix this and while testing it, we found out that
the from ID can also be different. So basically we want to get the from ID from the incoming chain but rather it was taking from ID, from its local state. So we fix that issue as well. And then updated this PIP last week and hence like both the issues has been resolved in this PIP. This, this is basically. The overview and the fixable fix for this is that we calculate to such that it remains same for both. The chains like incoming like while importing and new chain from a York. We take, we calculate two such that to value will be same on the current chain as well as the imported chain and same. The from ID will be taken, from the import, like the chain, which is being imported rather than the local one.
Yeah, so for this, we have added and additional field which is the delay that we are adding to calculate the value of 2. So basically we say that two value will be calculated in such a way that it will be current block minus 128 seconds. So that it will be like, let's say, the current blocks, timestamp is t. So the two parameter past to the himdal will be t minus 128 seconds across all the forks which is importing. This particular chain in the parameters from id as well as two is the same. The transisting transactions written from him. That will be the same and hence we won't get any bad block issues and those the The depth of there you are will not be affected.
Like at all whatever whatever the size of the incoming changes, you can see this implementation and also like this has been included in the current beta release, which has been released for Mumbai Network. Yeah, that was the overview. Now, we will discuss like that testing approach that we have. Use for this. So basically we tested this using matic CLI. So matic CLI is basically a tool which we can use to create our own devnet where we can basically through provide. The number of valiators, we want the number of centuries you want and the number of century nodes from Aragon as well, we want in the network. So ideally we have, we
Like took enough centuries as well as valiator nodes, as well as we included, Aragon, centuries as well in the network with this fix and without this fix. So initially you wanted to test if this is the actual root cause of the battle block issues. And we basically simulated this particular issue that happened on the main net and we're like successfully able to do that After that, we added this fix and try to again create this scenario. So basically the scenario was Let's say, we had four validators of same stick. We just disconnected. One validator from the three other validators and made sure that number of states in transactions. So basically, we basically created two forks. First fork was
Valuator AI alone. And the second for was validator, which included valuator A B C. And we made sure there are enough number of centuries connected with only A4 and enough number of centuries connected with only before, now after some time. And like, during this, we were constantly sending transactions as well as state sync transactions. To the to both the forks. So that there are enough number of states in transactions, when it queries, from himdal. now let's say we are at Block 32 where we're with strange lens 16, Basically where bore will query number of states in like the states in transactions, from its same job, we made sure that the number of transactions chasing transactions received to both this works very different so that we we get
Bad Luck Error. Ideally, we should get bad luck error without this fix when we merge this back. So after
Like we tested various number various reals of different lens. Ranging from 10 blocks 16, blocks to 200 blocks as well, where the, where, the size of the incoming chain was like two like as long as as large as 200 blocks. Now, when we merge this chain. So basically, when we connect validator A to rest of the network basically validated bc, BCD. As validator, A was alone, he the number of blocks produced by him where very less because it used to produce block in duration of four seconds. Whereas the other therefore used to create blocks much faster because they were the primary producer now,
No. Yeah. So basically, it was obvious that and also looking at the length of the chain, it was obvious that validator A will import for B. Now, when he did that, we added a significant like a lot of logs to see what is the value of 2. And from that is being used or basically fetched from the incoming chain, and we like, basically, with this fixed, we found out that the two value was the same in for a while, importing the block as it was in in, for B when it was actually querying the chasing transactions from himdal, which means that the, that the fix work in this case. But with the initial fixed, we found out that even after two value is same, it was still getting bad blocks there. And then we found out that this is because the from ID was different.
Because the from ID was initially being fetched from the local state. instead of that from the incoming state, and this is the same issue that Was cost earlier by the difference in two value. Therefore, we applied a fix as well, where from id, instead of improving it from the local state, we import from the incoming state, and hence, we created similar, Scenario and tested this fix and found out that this like the bad block error didn't happen. And we have tried this. on like different scenarios, taking arrogance, entries into the picture as well, and making sure that they are connected to a single validator, who is on a different forks, as well as Like also started kept a node.
Offline during the hard work, made it saying from scratch and all such things and there were no issue over throughout the testing. So yeah, that is The whole testing that we did, and we did multiple rounds of this.

**Sandeep Sreenath:** Thank you, thanks a lot. Pratik of detailed description. Yeah, and also Harry should do we take questions now or we have to all the presentation?

**Harry Rook:** Yes. I was about to say if anyone's got any questions for Pratik or Sandeep, either around testing at the technical details, or around rollout on Mumbai and then scheduling for Mainnet, then

**Alex PFL:** Um, I have a question if no one else does. One of the things I've noticed is um you know, because cuz we're fasting like we're connected to a lot of nodes and a lot of validators and so one of the things I see is like bad blocks, just kind of like bouncing around the ecosystem and I was wondering like on one hand. I think that all these like steps that you're talking about are amazing and I think it makes a lot of sense and I'm super excited for this. Um, what I was wondering is Is there anything in motion that's going to help us be like, you know, more proactive when it comes to like propagating, you know, some of these like blocks that might not be accurate or or is that even Accurate way of looking at it or even like a reasonable a goal.Right.

**Sandeep Sreenath:** Yeah, we will have to take it is by case basis and then figure out, you know, what else is, you know, causing these bad blocks. So like I said, most most of the cases what we have seen is when himdal, for example, is not in sync because Then when Bore is trying to fetch the state sync, you know, records from him doll, it's not able to either get any records because it's still catching up,â€¦
like him does still catching up or him doll is completely down. So, like these are some of the major reasons and then the other reason being, you know,

**Alex PFL:** That makes sense. One of the ideas I was thinking and this is like, a total longshot, so, please stop me. If this is like way too out there, but it feels like like, you know, when we see all these like, you know, bad blocks on our end, it's like, you know, our know things that the bad block because our Heimdall is saying that but the note that sent it to us that were paired with and that you know, we're in consensus with on the bore side. Doesn't think it's a bad block because it's time doll is probably you know, marching to a totally different beat. And so what I was wondering is like maybe there's some room for us to try to make it so that like if, if more nodes are peered together, then maybe their corresponding heimdall nodes are going to be trying to synchronize with each other. It seems like if the board notes appeared, they're sending stuff to each other, but it seems like, you know, keeping like the more data flow on both layers, rather than like, you know, too totally different P2P network might help like,
Stop propagation of blocks that are maybe not. I'm just kind of thinking out loud. But like something along those lines like more homogeneous peering between the two systems. Is that, is that something that might make sense or is that It's probably pretty infeasible to come a text standpoint as I think about it.

**Paul O'Leary:** I mean I'll try to tell me a little bit. I don't think. Think it might be a little bit off to characterize it. As, as bad blocks being propagated, the what we have to understand aboutâ€¦
what the bad block error is, is that The so, so you know, for better for worse, like it or not basically, you know, we have the tree orgs and, and they're an issue. And so we're it's system is having to deal basically, with the scenario of having kind of often being on a fork basically, and then seeing a different fork, the bad block error is only when Whatsoever to say. It basically is only when it kind of just as like checking the math of the other of the block that it's getting, and it's incorrect. And and the mass should always be correct, even if it doesn't turn out to be the canonical fork, basically, the, the bookkeeping should always be correct. And so that's kind of what this area is. And the other thing that people should be aware of, is that, you know, we've been talking about this, this proposed upcoming hard fork. There's actually a lot of other ants Larry fixes and kind of improvements around this area basically. So making sure for instance, that we always
I think there was a bug fixed basically where sometimes when we queried Heimdal, if it didn't have the right answer it would it would say nothing and and it kind of needs to make sure that like if it doesn't have the right answer, it it says it doesn't have the right answer and so that the local node doesn't kind of try to make a definitive request. So there's lots of other stuff kind of improvements around here. It's just the hard work. It's kind of the main thing we have to coordinate. So So that's just kind of a brain don't basically.
Like I said it's don't think of the bad blocks as the way to think of it correctly. Basically is it's just like the node gets a You know gets a potential block from another node and then it checks the math and part of what it has to do to check the math is is if their state SIG transit, it has to see if this should be states in transactions of the block as well.
Basically, it doesn't mean that it's going to end up being the canonical fork. It just means that it's kind of bookkeeping, right? Go ahead. Sorry.

**Alex PFL:** Got it. Got it. Now, that makes sense. So we'll see those error messages. Even if it's You know, not the header or not, not that not the head.

**Paul O'Leary:** Yeah, well, that's, that's the thing. Is you really shouldn't be seeing bad? Block errors, basically, it's kind of there's in the steady state and so I obviously, We so so I mean obviously what I think what we should do here basically is, we should get through the hard fort and get through these improvements and then maybe we should circle back with you basically to see if you're still seeing the prevalent and because that again, the bad block, errors is almost like a. This should not happen type air, it's one of those. It's that class of arabies, it's not. It's even when the system is like You know, forking and reorging and stuff like that. You still really shouldn't see. Bad block here. So that I might, my advice would be, let's get through this hard work, get these improvements and basically, and then circle back and see if it's see if you're still seeing that phenomenon a lot anyway. So yeah.

**Alex PFL:** Yeah, yeah, I could talk for hours about this. I am we we track which notes propagate, the the bad blocks to us. And the weirdest thing is that like from time to time will literally get one from a validator, like not even a century. Like, we'll get one directly from a validator. And it's like How did that even make it to the validator before? Yeah, I don't want to derail

**Pratik Patil:** So the recent release in him does 0.3.4 Beta basically fixes this, this issue only. So if himdal is falling behind instead of Returning a result, which will result in a bad block. It basically says that says, in a way that it is out of sync and bore won't throw a bad block error instead, it will wait for him to get in sync, so that will reduce the number of hard rocks.
Thank you.

**Harry Rook:** Awesome. I have a questions on. PIP 12 Indor folk if not, we can move on cover the last bits of Album If sandeep, you have any other points there, you want to cover. But yeah, any more questions now, feel free.
**Sandeep Sreenath:** yeah, so manav from it will be covering with PIP 11, Milestones.

**Manav Darji:** Yeah so hi everyone. I will be talking about a bit about the Faster deterministic community, which you are bringing where milestones and how we, how we tested the whole feature from more and him that perspective basically. Yeah, we just briefing on what different sorts of testing have been performed for this particular feature. So yeah, just to give a brief overview on on the feature itself. It's basically, if you are, well aware of the checkpointing mechanism which we already have, it's basically taking some board blocks, summarizing them in form of a single hash root, hash, which we call and posting the data to L1. But of course, like the process isn't much frequent because it involves sending the data sending apart from this. Take my data sending all the signatures and everything to
The layer one, which is ethereum in our case, so it's like costly and time consuming as well. So we can't fully leverage it. And hence, we, we bring something called milestones which are, I would say us a kind of subject points, which are like smaller checkpoints, which are never sent to L1, but they stay until the layer of him that itself. So basically, him doll, as you all know, it's it's based on based on the enderman consensus consensus, enhance. It has single block finality. So we could we could actually leverage those single block finally because we could leverage him down to make sure that the more chain or the fears of the board chain up proceeding on a correct for and they are not the organ. For large number of blocks. Yeah, that's the basic.
Yeah, there are a lot of components involvement Basically. It adds this whole new type of message in himdal, which we call the milestone message, which is quite similar to the checkpoint message. And it's him that is responsible for creating more. Getting those range of blocks and, and proposing a new milestone and they're all like. So there's also voting around among all the evaluators, which are presentation network for that particular milestone. And yeah, once it gets finalized board, can actually leverage it right away to follow a fork or so there are multiple things which more is Boris a part of. So first thing is it needs to find new peers and then it needs to import blogs from the existing peers. So these are the major two places where it could leverage this particular thing. So yeah,
It will right at least this whitelist this checkpoints and milestones as well in basically new data storage which is there and it will try to leverage those things. Then when it when it tries to import a block or connect with the peer In with, with a name to import blocks, right? And and post this, what a good thing, which we have would be this finalized that, which is quite similar to Ethereum, where you could query, which was the last finalist block and query the data for that particular block. So yeah, this is the PRP which details out a lot of internal things. There are a lot of other moving components as well, for this particular Pap. Yeah. Which are, I think, I guess already discussed in one of the previous calls.
Yeah, this is the whole crux of the PIP. I, I quickly share about how how we proceeded to test this particular thing. So yeah, there are I mean, even the fact that it's a big feature and and there are multiple layers involvement. We we took my, we took with, we had different approaches for testing, so like I would briefly
diversify them into four, three, four big topics. So one of them is unit tests which is a much common practice, which we generally follow for every new feature. So yeah, basically, there as given the fact that there are a lot of components involvement, the storage, the processing and validation of milestones, a few important modules have been impacted like the download or the folk choice rule. So it's very important to test each of these individual individual components on its own. So basically, of course, like testing the whole system altogether, like clubbing, everything just to make sure that it works is a separate thing. But like independent feature, if like independent components should also work and hence, we have included test,
And how have had a good separation of concern while testing each of these components. So we have extensively used, mocking to mock a lot of components and then test things in isolation, which has helped the helped us improve the whole feature as well as like, help us get a lot of edge cases. So yeah, that's one thing. The second thing I would say would be into interesting. So This also is kind of a part of the unit test itself. So we like inside our client which is more, we have ability to like create a whole definite, kind of involvement where we where we like initialize different like multiple values where we
Like where we have my, like, each of them have their own chain, and each of them communicate with either each other to see how how the chain imports and everything work. So, yeah, we were able to do perform such kind of testing as well, then then it comes. Kind of black box testing which which we is, like, testing the whole feature externally through some external component. So for that, like, Yes, I think pratiko ultimate mentioned we've been using express cli or like magic CLI. I would say years one of the dog, which we
How it's a great short document, but yeah might be helpful. So, yeah, it's basically. We've done a lot of scenario-based testing where we simulate or if different kind of conte conditions, where we simulate network partitions and we basically check how how the milestone behaves, how the whole network behaves with and without milestone as well. And yeah, we have like you try to incorporate some basic basic cases, which can be, of course, extended to like, create more complex cases later on. But yeah. So these are some of the cases which we've been able to test why I just cla. And yeah, of course, like, even the fact that it's a, it's an open source, repository
They others can also spin up dimitri's and test the whole feature itself with these instructions, given below. So yeah, that's a good thing. If anyone from the community wants to be involvement in the testing and of course, like the last part is manual testing. Like it of course it doesn't you know help us with late with some rigid structure. But of course doing it. Comprehensively gives us more confidence on a lot of things like how the milestone processing has been happening on him dial. How is board leveraging it? Fear connectivity, testing testing with different sort of setups where, and different sort of, network partitions, as well. Making sure the whole place will work and late. We have also tried to bypass a lot of code components to see how when you talk behaves,
So a lot of those kind of testing has been involve to make sure that the whole feature together fits well and gives us expected outputs.

**Sandeep Sreenath:** Thank you. Thanks a lot Manav. Yeah, I guess we are open to questions again on the Mike Stones and for our topic as well.
Or if there are any, you know, we could also probably take it towards the end of the call, because I think we still have one more topic to cover Harry, which is Block Hdmi parallel area.

**Harry Rook:** Yes. Yeah, there's a couple more things, but I think just just to wrap all that up. I think it may be worth just going over briefly like the decisions around. Kind of which fork affects like the execution client and the consensus client and how you know the indoor fork obviously been the consensus client. Um, you know, while there was a separate and you know, what will be the dependencies that you'll be looking for before or after the, the consensus focused essentially the the indoor fork?

**Sandeep Sreenath:** yeah, so basically Indoor Fork is an upgrade in bore and working board and it's completely independent of him done, but for milestones like Pip 11, you know, so we have A dependency on board as well as him done. But then it's not a hard fork on board, but it's just a hard fork, it's going to be hard fork on him does. Yeah. But but for the milestones feature to work properly, there is a version of core that we will be releasing, you know, before the hard for, you know, happens on him, done that, that's again, like I said, it's it's just to ensure that the feature is working. Fine, you know, we are able to best utilize it to the best extent. So yeah.

**Harry Rook:** Awesome. Yes.

**Sandeep Sreenath:**  Does their question Harry?

**Harry Rook:** Yeah. And if there's no, if there's no questions on that, then. Yeah. We can move on to parallelization. I think we've got Jerry here. Yeah, so yeah. Thank you enough Sandeep and Pratik. Thank you for those? Good overviews Jerry. Are you here? I think you were earlier. Yeah, Jerryâ€¦

**Jerry Chen:** Yep, I'm here.

**Harry Rook:** if you want to do with parallisation then yeah feel free to take it away.

**Jerry Chen:**  Cool. Thanks. Eric. Yeah. So In general. Paralyzation is, you know, as you know We're trying to execute transactions in parallel within a block. And this work was inspired by.
Blockchain, which was a paper reading by Aptos. And last year's sometimes last year, we probably should article briefly introduced the entire concept of parallel execution. And basically, we found that, you know, within the block in general, in our boardman nets, The transactions could be paralyzed in certain way. So one really important concept is that sometimes transactions in the blog can depend on each other. For example, like, multiple contract, multiple transactions are trying to interact with the same contract, then there's, you know, he has to be executed in sequence in the sequence. And they could not be applied, like, in parallel,
so what we have found is that the  paralizability of like, the average paralelised ability, within the block is a roughly 2x, which means that like, you can paralyze the longest execution path is generally, 50% of the blog. And so that's what we're talking. It targeting ads, the speed up of the an imports and currently what we have done so far is to implement these paralyzation in board and during the chin imports. So there's also these, you know, two concepts, one is executing
And validating the blog and the other is generating or, you know, mining a new blog. Currently, there's no changes to maintain or mining. The new blog, these work will still be, you know, done in a sequence like what we do in the past. However, these importing of the new blogs is going to be paralyzed with the next major, you know, upcoming release and it's not a change to the consensus level is simply, you know, because there's nothing change in terms of generating the new block so that the clients, which imports the blog will get the benefits. And it does not affect, you know, how or the consensus agree on. You know what block is valid or not, and we have found pretty good results that with the help of Paralyzation, the block Val.
Session. And propagation time has dropped significantly with these changes. Yeah. So that's the like a very high level introduction of our paralyzed execution and an ongoing effort is actually Thinking if we are able to take these to another level, right? So currently what we're doing is we up optimistically executes transactions in parallel as fast as possible. And we have these some kind of validation, that's tries to detect the written rights of each transaction. And if we see a conflicts say, for example, like if transaction one depends on transaction zero,
and transaction one executes before transaction, zero completes then what's going to happen is transaction. One will try to read the data from directly from the storage instead of from the results that has been written by a transaction zero, right? So that would result in a wrong place, wrong execution, outputs of transaction one. And and these validation processes to prevent any situation like that. And we're trying to make sure that, you know, even if the even if this happens will re-execute transaction one so that you can read the correct outputs from transaction zero.
Right. So these process with what we do here sometimes can be you know, lead to longer time of validation or along the time of or more resources or computational resources being spent In the block execution. So, what we're trying to do next is to Actually include the dependency data about these transactions in the block header. So that receiving a new blog, the note itself knows exactly how these transactions depends on each other so they can schedule the execution more efficiently, without re-executing the transactions.
Because of this conflicts. Yeah. So that's the you know, that's what we like to do and these will Potentially change how the, you know, the consensus, or how the block structure work, because we have to insert this dependency metadata into the block header, right? So because of that where currently writing a new PIP for for these I'm currently working on it and yeah. So once we have something have these drop the peep available we'll share with the community and ask for for the feedback. Yeah. Especially regarding, you know how we want to
Could this data in the blog? Header for example whether we want to add a new fields or adding it to existing field called extra data, so that is still under discussion. Yeah, so we'll be sharing more information in the future.

**Harry Rook:** Awesome. Yeah, thank you very much for that. Jerry, it's super interesting. Yeah, if there's any questions on that, I've seen a bunch in the chat but yeah if you guys want to ask the questions now we've got three minutes and then I want to pass it over to Alex. He's got an agenda point on me Visa. I don't want to make him way all this time and then I have any time to speak. So yeah, there's any questions and feel free to ask.

**Alex PFL:** You could send me your telegram, I'd love to bounce with you ideas off youâ€¦
more focused. And I guess like Sandeep too and and pratik about the black building more. So than the block processing. This is, This is gonna be huge. I feel like the amount of like processing time, spend doing like, you know, just this data is like, it's huge. It's, it's such a I'm a big fan, love it.

**Jerry Chen:**  Awesome. Yeah. Thanks Alex. Yeah yeah I'll post my take them ID in the chat so yeah you can like reach out to me anytime.

**Sandeep Sreenath:** Sure. Okay. Yeah, so maybe Alex, we can discussion the forum and then of course, if there are more deeper questions, we can definitely connect through other meetings, Yeah, thanks. Thanks.

**Alex PFL** Very cool. Thank you Tom. I'm excited for this. I feel like like from an MEV standpoint Whenever we talk about transaction ordering and parallel processing, that tends to open a lot of doors. I'm excited to see what the possibilities are here.

**Harry Rook:** Thanks if there's never questions. I think that's quite a nice segue into into Alex. Also, take it up.

**Alex PFL:** Yeah. Well thank, thank you, thank you. Um, I looked at the the roster and I'm pretty sure everybody here knows me. But for the, for the one person who doesn't my name is Alex. I go but guard in the discord and on Twitter and I'm the CEO of Fastlane which is polygon's native, we are not run by polygon. We're a third party, but we're polygon's native and easy protocol. We are just to bring all of you up to speed. We are very different from flashbacks. Um, our primary focus when we're building on polygon was to protect users because that seem to be the general consensus among validators. Is that validators didn't really want to make money if it meant taking that money from users. And to also, you know, because let's be honest running polygon that it's not the, easiest type of to run, we want to make the process is non-invasive.
Paul. And we didn't want to create any sort of infrastructure dependencies because we didn't want the polygon Labs team you guys, the blame us if any validators using our system, never attract. And so far, it's been working really great like our entire system. Like we are like incidentally, we are, you know, by far the, you know, most decentralized of all the immediate protocols, we actually just enabled. This is a big news. We just enabled transaction submission just by putting the bundles into the memory pool, which is huge. I don't know of any other any of the relay on any game that allows stuff like that. So we're super happy we're you know blazing a trail and doing things very differently but it's very exciting. Um that being said, the reason why the speak today is because when I look at how immedi protocols and blockchains interact on other channels, it's usually a lot more antagonistic than the relationship I have with most of you guys.
The usual way things go on, a lot of other changes is the immed. Protocols will be trying to you know like Take advantage of users a little bit more in the, You know, the the channel be like No I don't know about that and the MVP protocol will be trying to centralize a little bit more in the channel. You know. The foundation may be like Maybe not a good idea. And so there's this like kind of, you know, I don't want to say Give and take But there's a sort of like, You know, Supervision Aspect of it, where, you know, if the MeV protocol isn't monitor closely then always the, You know, possibility that they could end up doing things that are either, you know, centralizing or harmful for users and oftentimes both because that is unfortunately the kind of like natural direction of enemy. We are you know the exception to that um but I want to make sure that everyone here has the tools to verify that and so with with my time I just wanted to briefly show you guys a little bit of like how you can see what we're doing.
And how you can kind of read into that and how you can monitor things. Um, One of the like, really neat things about us is that we are the only MVP protocol where all of our MeV is done via smart contract. What that means is that every single bundle that comes through the fastlane protocol, And, by the way, we are connected to about a quarter of the, the chain, right now, roughly 25% of all blocks or a quarter of all blocks, are made by validators system. I think that number might be going up, actually just on board, another validator this morning. So, it's it's a big thing. And it's, it's definitely worth making sure that the community and that governance has the power to monitor. So when we share my screen with you guys a real fast, so,
can you guys see this? I should just be the the Polygon Block Explorer. Are you guys able to see this?
Cool. So the neat thing about a fast line is that every single transaction that comes through us every single searcher bundle whether they're trying to back on or you know liquidate someone on ave or you know like like back on somebody on quick swap or uniswap, Every single one of them comes through this one singular smart contract and you can get these smart contracts address from our website. But the neat thing here is that you can literally always look and see, you know, Hey, what are the bundles like what's going on? Which validators are processing them. How much you know, revenue are they collecting? Is there are there any users being taking advantage of all of the data is right here on this smart contract? There's not any sort of like, You know, private like, you know, hidden transactions or anything like that. We are very big believers and finding a very bright light on everything that is. Anyway, um, as an aside, That's actually how we protect users is we make sure
That when searchers, when like box, send us bundles, we take every content like every transaction in those. Bundles, a new broadcast, it out into the entire blockchain into the public memory pool. If you guys remember back, like, I think it was three months ago. There was this, like, exploit on ethereum Mainnet where some sandwich spots ended up losing almost 24 million dollars because they're sandwiched transactions were leaked out and taking advantage of by another sandwich here. Um, that's actually the way we build fast line is we intentionally do that every time we always leak out all of the transactions that we get the our relay, because we want to make sure that if anyone is trying to do something illegitimate, then there are other searchers who are in place to make bundles of their bundles. And it has this great effect of like honestly, right now if you were going to do it, transaction polygon is the best execution environment of any EV
There's less than a 1% chance. Like, right roughly one percent chance of getting sandwiched because there's I think the only like, two validators that do the, the sandwiching style of the navy. And like, that's like, it's like small and no other chain has as good. An execution, as polygon another chain has like validators as on board, with protecting users as polygon. And I think that's really cool.
But don't take my word for it. You should always verify because it may be protocols are not to be trusted. So, um, everything we do comes through our smart contract, and you can see our smart contract here. Again, the contract address you can find on our website. Um, if you ever want to dig into any of these bundles, it's fairly straightforward. What she can do is you can just click on any of these transactions. Um, you'll note that a lot of these transactions have reverted. That's because, as I mentioned before we broadcast every transaction out into the memory pool. And so we do not give searchers the ability to have like a free revert. You know, if they send us a transaction, they're transaction is going to go on to the chain. So, what we can do is we can Oh Harry, am I going over time?

**Harry Rook:** Yeah yeah sorry not not to interrupt you but yeah we've we've only got a couple minutes left on the call and yeah, we need to wrap it up shortly. So if you could

**Alex PFL:**  Absolutely. So to bring it full circle, just go to any transaction on the Smart contract. Take the transaction. Hash go to Our Explorer, which is also linked on our website. You can put the transaction hash into the Explorer.
And you can see, not just the auction results, but you can also see all of the bids from all the searchers who didn't win the auction. You can see the time that these transactions were received and you can also see the transactions and information on some of the bids from searchers who didn't even make it in time who sent their transaction. And before, like, when it was too late, um, it's like a full view. Like, You can see everything that comes through our relay, and I just want to make sure that everyone in the community is empowered to, you know, shine a really bright light and you have just full power to observe everything that happens when it comes to polygon anything. And yeah, that's it.

**Harry Rook:** Awesome. Thank you Alex. Yeah I mean if there's any questions then feel free to ask these now, we've got a couple minutes left so Yeah. Any questions? Feel free to ask if not we can we can wrap it up.
Awesome. Yeah, well I think that covers it then the next ppgc will be on the 13th of July. So keep an out for that. There is a lot coming up in terms of pipeline for upgrades. So we may be increasing the frequency of these calls to once every two weeks. So if and when that happens, I'll let you guys know on this call. Yeah again, thank you for everyone that spoke today. I think there's some really good discussion. So yeah, enjoy the rest of your day guys. And I'll see you next month.
Cool. Okay, we'll have to jump guys, but thank you all again and see you next month.

#### Meeting ended after 01:00:31 ðŸ‘‹
